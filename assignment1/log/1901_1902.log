Script started on Fri 11 Sep 2015 02:16:18 PM PDT
]0;cloudera@quickstart:~/workspace/real-time/assignment1[?1034h[cloudera@quickstart assignment1]$ exitcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs -get output[15@MaxTemperature 1901[C[C[C[C[C[C[C[12Pdfs -put 1901 export HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Khdfs dfs -lsrm -r myNewDirls[Kmkdir myNewDirls[K[Ks /[Ksmkdir myNewDirls[Krm -r myNewDirls[K[8Pexitjavac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ javac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs -get output[15@MaxTemperature 1901[C[C[C[C[C[C[C[12Pdfs -put 1901 export HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kjavac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cr -cf ajr619-hw1.jar *.class[K
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ jar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs -get output[15@MaxTemperature 1901[C[C[C[C[C[C[C[12Pdfs -put 1901 export HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cr -cf ajr619-hw1.jar *.class[Kexport HADOOP_CLASSPATH=ajr619-hw1.jar
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ export HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs -get output[15@MaxTemperature 1901[C[C[C[C[C[C[C[12Pdfs -put 1901 export HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classexport HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[19Phdfs dfs -put 1901 [K[K[K[K[Kinput
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ hdfs dfs -put inputexport HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs dfs -get output[7Pwc -l output/hdfs dfs -get outputls[Khdfs -get output[15@MaxTemperature 1901[C[C[C[C[C[C[C[12Pdfs -put 1901 MaxTemperature 1901 output[C[1P output[1P output[1P output[1P outputi outputn outputp outputu outputt output
15/09/11 14:17:49 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/11 14:17:51 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/11 14:17:52 WARN security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://quickstart.cloudera:8020/user/cloudera/output already exists
15/09/11 14:17:52 WARN security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://quickstart.cloudera:8020/user/cloudera/output already exists
Exception in thread "main" org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://quickstart.cloudera:8020/user/cloudera/output already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:564)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:432)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1306)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1303)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1303)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:564)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:559)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:559)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:550)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:835)
	at MaxTemperature.main(MaxTemperature.java:24)
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ hdfs MaxTemperature input output1
15/09/11 14:18:16 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/11 14:18:18 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/11 14:18:21 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/09/11 14:18:22 INFO mapred.FileInputFormat: Total input paths to process : 2
15/09/11 14:18:22 INFO mapreduce.JobSubmitter: number of splits:2
15/09/11 14:18:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1441995117100_0002
15/09/11 14:18:24 INFO impl.YarnClientImpl: Submitted application application_1441995117100_0002
15/09/11 14:18:24 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1441995117100_0002/
15/09/11 14:18:24 INFO mapreduce.Job: Running job: job_1441995117100_0002
15/09/11 14:19:00 INFO mapreduce.Job: Job job_1441995117100_0002 running in uber mode : false
15/09/11 14:19:00 INFO mapreduce.Job:  map 0% reduce 0%
15/09/11 14:20:01 INFO mapreduce.Job:  map 100% reduce 0%
15/09/11 14:20:37 INFO mapreduce.Job:  map 100% reduce 100%
15/09/11 14:20:41 INFO mapreduce.Job: Job job_1441995117100_0002 completed successfully
15/09/11 14:20:42 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=144425
		FILE: Number of bytes written=619323
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777384
		HDFS: Number of bytes written=18
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=112914
		Total time spent by all reduces in occupied slots (ms)=36498
		Total time spent by all map tasks (ms)=112914
		Total time spent by all reduce tasks (ms)=36498
		Total vcore-seconds taken by all map tasks=112914
		Total vcore-seconds taken by all reduce tasks=36498
		Total megabyte-seconds taken by all map tasks=115623936
		Total megabyte-seconds taken by all reduce tasks=37373952
	Map-Reduce Framework
		Map input records=13130
		Map output records=13129
		Map output bytes=118161
		Map output materialized bytes=144431
		Input split bytes=216
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=144431
		Reduce input records=13129
		Reduce output records=2
		Spilled Records=26258
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=2146
		CPU time spent (ms)=14960
		Physical memory (bytes) snapshot=567631872
		Virtual memory (bytes) snapshot=4508090368
		Total committed heap usage (bytes)=392306688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1777168
	File Output Format Counters 
		Bytes Written=18
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ hdfs MaxTemperature input output1[K[13Pdfs -put inputexport HADOOP_CLASSPATH=ajr619-hw1.jar[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[8Pjar -cf ajr619-hw1.jar *.classvac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-0.20-mapreduce/*:/usr/lib/hadoop-hdfs/* *.java[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcat output/_SUCCESS [2@part-00000[C[8Pls -lh output/[1P output/wc[C[C[C[C[C[C[C[C[C[C[Chdfs dfs -get outputls[Khdfs dfs -get output1
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ cat output1/
part-00000  _SUCCESS    
[cloudera@quickstart assignment1]$ cat output1/
part-00000  _SUCCESS    
[cloudera@quickstart assignment1]$ cat output1/part-00000 
1901	317
1902	244
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ hdfs [Kcat output1/_SUCCESS 
]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ ls
[0m[01;31majr619-hw1.jar[0m  mapreduce_output.script  MaxTemperature.java         MaxTemperatureMapper.java    MaxTemperatureReducer.java  typescript
[01;34minput[0m           MaxTemperature.class     MaxTemperatureMapper.class  MaxTemperatureReducer.class  [01;34moutput1[0m
[m]0;cloudera@quickstart:~/workspace/real-time/assignment1[cloudera@quickstart assignment1]$ exit
exit

Script done on Fri 11 Sep 2015 02:24:04 PM PDT
